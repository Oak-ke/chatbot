import json
import re
import os
import logging
import pandas as pd
from langgraph.graph import StateGraph
from typing import TypedDict
from langchain_core.messages import HumanMessage
from utils import detect_language, translate_text
from llm import llama_llm
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.utilities import SQLDatabase
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from visualizer import Visualizer, FileDataSource, MockDataSource
import uuid
from dotenv import load_dotenv

import matplotlib
matplotlib.use("agg") # This for headless plot graphs(Use before pyplot import)

# Configure logging
logger = logging.getLogger(__name__)
load_dotenv()
llm = llama_llm()

# State definition
class State(TypedDict):
    question: str
    language: str
    intent: str
    data: str | None
    answer: str
    graph_url: str

# Intent mapping
INTENT_MAP = {
    "system_name": ["system name", "name of system", "what is the system called"],
    "system_info": ["system_info", "system information", "about system", "info", "tell me more"],
    "cooperatives_total": ["cooperatives_total", "number of cooperatives", "cooperatives registered"],
    "members_total": ["members_total", "total members", "members", "female members", "male members"],
    "members_by_state": ["members_by_state", "members per state", "members by state"],
    "female_members": ["female members"],
    "male_members": ["male members"],
    "directors_total": ["directors_total", "number of directors", "directors"],
    "visualize": ["visualize", "graph", "plot", "chart", "show me trends"]
}

# Database setup
db_uri = os.getenv("DB_URI")
db = SQLDatabase.from_uri(db_uri)

# Allowed tables that the LLM is allowed to query
ALLOWED_TABLES = {"member", "cooperative", "director"}

# Helper functions
def get_schema(_):
    """
    Return schema information for allowed tables.
    Used for LLM to understand table structure when generating SQL.
    """
    return db.get_table_info(table_names=ALLOWED_TABLES)


def sanitize_sql(sql: str) -> str:
    """
    Remove any markdown code blocks and trailing semicolons from SQL.
    """
    sql = re.sub(r"```sql|```", "", sql, flags=re.IGNORECASE)
    return sql.strip().rstrip(";")

def validate_sql(sql: str) -> None:
    """
    Ensure that only allowed tables are referenced in SQL.
    Raise an error if invalid tables are used or no table is referenced.
    """
    sql_lower = sql.lower()
    tables = set(re.findall(r"\bfrom\s+(\w+)|\bjoin\s+(\w+)", sql_lower))
    tables = {t for pair in tables for t in pair if t}

    if not tables:
        raise ValueError("No table referenced")

    illegal = tables - ALLOWED_TABLES
    if illegal:
        raise ValueError(f"Illegal tables used: {illegal}")
    
def run_query(query: str):
    """
    Sanitize and execute the SQL query against the database.
    Returns the query results.
    """
    sql = sanitize_sql(query)
    return db.run(sql)

# SQL generation
def write_sql_query(llm):
    """
    Generates a Runnable that will create SQL for a user question.
    Uses a ChatPromptTemplate to instruct the LLM on exact columns to use.
    """
    sql_template = """
        You are given a MySQL database schema.

        CRITICAL RULES:
        - Use EXACTLY these tables and columns:
        - cooperative: cooperative_id, cooperative_name
        - member: member_id, cooperative_id, member_name
        - director: director_id, cooperative_id, director_name
        - Do NOT invent column names like 'id' or 'name'
        - Always reference these columns exactly as above
        - Use JOINs only via foreign keys
        - Prefer INNER JOIN
        - Use aggregations when needed
        - Return only ONE valid SELECT statement
        - Do NOT explain, comment, or use markdown

        Schema:
        {schema}

        Question:
        {question}

        SQL:
    """

    # Define LLM prompt msg
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                You are a SQL generator. Always use the exact column names:
                - cooperative: cooperative_id, cooperative_name
                - member: member_id, cooperative_id, member_name
                - director: director_id, cooperative_id, director_name
                Return ONLY valid SELECT SQL. No explanations.
                """
            ),
            ("human", sql_template),
        ]
    )

    # RunnablePassthrough allows the prompt to access the schema dynamically
    return (
        RunnablePassthrough.assign(schema=get_schema)
        | prompt
        | llm
        | StrOutputParser()
    )

def generate_valid_sql(question: str, llm, max_retries: int = 2) -> str:
    """
    Generate a valid SQL query from the user question.
    If invalid SQL is generated by the LLM, retry up to max_retries.
    Validates table usage before returning SQL.
    """
    error_message = None

    for _ in range(max_retries):
        sql = write_sql_query(llm).invoke(
            {
                "question": question
                if not error_message
                else f"""
                        Previous SQL was INVALID.

                        Error:
                        {error_message}

                        Rules reminder:
                        - Use ONLY tables: member, cooperative, director
                        - Do NOT invent names
                        - Output ONE valid SELECT

                        Original question:
                        {question}
                    """
            }
        )

        try:
            validate_sql(sanitize_sql(sql))
            return sql
        except Exception as e:
            error_message = str(e)

    raise RuntimeError(f"Unable to generate valid SQL: {error_message}")

# Natural answer generation
def answer_user_query(question: str) -> str:
    """
    Executes the generated SQL query and converts the result to natural language using LLM.
    """
    sql = generate_valid_sql(question, llm)
    response = run_query(sql)

    # Prompt LLM to create human-readable answer
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "Given an input question and SQL response, convert it to a natural language answer. No preamble.",
            ),
            (
                "human",
                f"""
                    Schema: {get_schema(None)}
                    Question: {question}
                    SQL Query: {sql}
                    SQL Response: {response}
                """
            ),
        ]
    )

    messages = prompt.format_messages()
    return llm.invoke(messages).content

# Language detection and translation
def detect_lan_and_translate(state: State, llm):
    text = state["question"]
    lang = detect_language(text)
        
    if lang == "en":
        return {
            "question": text,
            "language": "en",
        }
        
    translated, _ = translate_text(text, llm, target_lang="English")
    
    return {
        "question": translated,
        "language": "ar"
    }

# Intent detection
def detect_intent(state: State, llm):
    """
    Classify the user's question into one of the known intents.
    Returns canonical intent string.
    """
    prompt = f"Classify the intent into one of: {list(INTENT_MAP.keys())}\nQuestion: {state['question']}"
    raw_intent = llm.invoke([HumanMessage(content=prompt)]).content.strip().lower()

    # Normalize to canonical intent using substring matching
    for canonical, aliases in INTENT_MAP.items():
        if any(alias.lower() in raw_intent for alias in aliases):
            return {"intent": canonical}
    return {"intent": "unknown"}


# Data selection
def select_data(state: State):
    """
    Depending on intent, either return system info or query database for relevant data.
    """
    if state["intent"] in {"system_info", "system_name"}:
        return {"data": "This system manages cooperative data dynamically from MySQL."}

    # For other intents, generate SQL and query database
    return {
        "data": answer_user_query(state["question"])
    }


def generate_answer(state: State, llm):
    """
    Prepare the final answer. Returns data if available, otherwise a fallback message.
    """
    return {"answer": state["data"] or "No data found."}


def visualize_node(state: State):
    temp_path = None
    # Determine strategy
    if os.path.exists("data/public_data.json"):
        # We need to transform the JSON structure into a flat DF for visualization if possible
        with open("data/public_data.json", "r") as f:
            raw_data = json.load(f)
        
        # If it's the members_by_state, it's easy to visualize
        if state["intent"] == "members_by_state":
            df = pd.DataFrame(list(raw_data["members_by_state"].items()), columns=["State", "Members"])
            # Temporary file strategy for this specific DF
            temp_path = f"data/temp_{uuid.uuid4().hex}.csv"
            logger.info(f"Creating temporary CSV at {temp_path} for intent '{state['intent']}'. Data shape: {df.shape}")
            df.to_csv(temp_path, index=False)
            strategy = FileDataSource(temp_path)
        else:
            strategy = MockDataSource()
    else:
        strategy = MockDataSource()
        
    try:
        viz = Visualizer(strategy)
        intent = state.get("intent", "unknown")
        safe_intent = re.sub(r'[^a-zA-Z0-9_]', '_', intent)
        output_filename = f"static/graphs/viz_{safe_intent}.png"
        graph_path = viz.analyze_and_plot(output_path=output_filename)
        
        if not graph_path:
            return {"graph_url": None}
        
        # In a web app, we want the URL relative to static
        graph_url = f"/static/graphs/{os.path.basename(graph_path)}"
        
        return {"graph_url": graph_url}
    finally:
        if temp_path and os.path.exists(temp_path):
            logger.info(f"Deleting temporary CSV at {temp_path}")
            os.remove(temp_path)

def route_to_answer(state: State):
    if state["intent"] == "visualize" or state["intent"] == "members_by_state":
        return "visualize"
    return "answer"


def build_graph(llm):
    """
    Build a StateGraph pipeline for processing user queries:
    Steps:
    1. Translate question if needed
    2. Detect intent
    3. Fetch relevant data from DB or system info
    4. Generate visualization if applicable
    5. Generate natural language answer
    """
    graph = StateGraph(State)

    graph.add_node("translate", lambda s: detect_lan_and_translate(s, llm))
    graph.add_node("intent", lambda s: detect_intent(s, llm))
    graph.add_node("data", select_data)
    graph.add_node("visualize", visualize_node)
    graph.add_node("answer", lambda s: generate_answer(s, llm))

    graph.set_entry_point("translate")
    graph.add_edge("translate", "intent")
    graph.add_edge("intent", "data")
    
    graph.add_conditional_edges(
        "data",
        route_to_answer,
        {
            "visualize": "visualize",
            "answer": "answer"
        }
    )
    graph.add_edge("visualize", "answer")

    return graph.compile()